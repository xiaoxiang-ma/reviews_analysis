{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Training: load corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from pyabsa.functional import ABSADatasetList\n",
    "# from pyabsa.functional import ATEPCCheckpointManager\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_reviews = pd.read_csv(\"Restaurant_Reviews.tsv\", sep='\\t')\n",
    "review_list = res_reviews.Review.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This script could only be used to manage NVIDIA GPUs,but no GPU found in your device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiaoxiangma/anaconda3/lib/python3.7/site-packages/thinc/neural/train.py:7: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  from .optimizers import Adam, linear_decay\n",
      "/Users/xiaoxiangma/anaconda3/lib/python3.7/site-packages/thinc/check.py:4: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  from collections import Sequence, Sized, Iterable, Callable\n",
      "/Users/xiaoxiangma/.local/lib/python3.7/site-packages/matplotlib/backend_bases.py:55: DeprecationWarning: PILLOW_VERSION is deprecated and will be removed in Pillow 9 (2022-01-02). Use __version__ instead.\n",
      "  from PIL import PILLOW_VERSION\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remote ABSADataset version: 2022.07.22 Local ABSADatasets version: None\n",
      "Unknown local version for ABSADatasets, please check the latest version of ABSADatasets at https://github.com/yangheng95/ABSADatasets\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open('aspect_extractor.pkl', 'rb') as file:\n",
    "        aspect_extractor = pickle.load(file)\n",
    "\n",
    "\n",
    "except: \n",
    "    print(\"FAILED!!!\")\n",
    "#     aspect_extractor = ATEPCCheckpointManager.get_aspect_extractor(checkpoint='english')\n",
    "#     with open('aspect_extractor.pkl', 'wb') as file:\n",
    "#         pickle.dump(aspect_extractor, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiaoxiangma/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# atepc_result = aspect_extractor.extract_aspect(inference_source=res_reviews.Review.tolist(),\n",
    "#                                                save_result=True,\n",
    "#                                                print_result=True,  # print the result\n",
    "#                                                pred_sentiment=True,  # Predict the sentiment of extracted aspect terms\n",
    "#                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Prepare for clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "  \n",
    "# Opening JSON file\n",
    "f = open('atepc_inference.result.json')\n",
    "  \n",
    "# returns JSON object as \n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    "  \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main = pd.read_json('atepc_inference.result.json')\n",
    "# main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "main = []\n",
    "for e, sentence in enumerate(data[:]):\n",
    "    single = []\n",
    "    if True:\n",
    "        single.append(e)\n",
    "        single.append(sentence['sentence'])\n",
    "        single.append(sentence['tokens'])\n",
    "        single.append(sentence['aspect'])\n",
    "        single.append([i[0] for i in sentence['position']])\n",
    "        single.append(sentence['sentiment'])\n",
    "        main.append(single)\n",
    "main = pd.DataFrame(main, columns =['sentence_id', 'sentence', 'tokens', 'aspect', 'aspect_loc', 'aspect_sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tokens</th>\n",
       "      <th>aspect</th>\n",
       "      <th>aspect_loc</th>\n",
       "      <th>aspect_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Wow . . . Loved this place .</td>\n",
       "      <td>[Wow, ., ., ., Loved, this, place, .]</td>\n",
       "      <td>[place]</td>\n",
       "      <td>[7]</td>\n",
       "      <td>[Positive]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Crust is not good .</td>\n",
       "      <td>[Crust, is, not, good, .]</td>\n",
       "      <td>[Crust]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[Negative]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Not tasty and the texture was just nasty .</td>\n",
       "      <td>[Not, tasty, and, the, texture, was, just, nas...</td>\n",
       "      <td>[texture]</td>\n",
       "      <td>[5]</td>\n",
       "      <td>[Negative]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>[Stopped, by, during, the, late, May, bank, ho...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>[The, selection, on, the, menu, was, great, an...</td>\n",
       "      <td>[selection, menu, prices]</td>\n",
       "      <td>[2, 5, 12]</td>\n",
       "      <td>[Neutral, Neutral, Positive]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>995</td>\n",
       "      <td>I think food should have flavor and texture an...</td>\n",
       "      <td>[I, think, food, should, have, flavor, and, te...</td>\n",
       "      <td>[food, flavor, texture]</td>\n",
       "      <td>[3, 6, 8]</td>\n",
       "      <td>[Neutral, Negative, Negative]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>996</td>\n",
       "      <td>Appetite instantly gone .</td>\n",
       "      <td>[Appetite, instantly, gone, .]</td>\n",
       "      <td>[Appetite]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[Negative]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>997</td>\n",
       "      <td>Overall I was not impressed and would not go b...</td>\n",
       "      <td>[Overall, I, was, not, impressed, and, would, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>998</td>\n",
       "      <td>The whole experience was underwhelming , and I...</td>\n",
       "      <td>[The, whole, experience, was, underwhelming, ,...</td>\n",
       "      <td>[experience, Sushi]</td>\n",
       "      <td>[3, 17]</td>\n",
       "      <td>[Negative, Neutral]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>999</td>\n",
       "      <td>Then , as if I hadn ' t wasted enough of my li...</td>\n",
       "      <td>[Then, ,, as, if, I, hadn, ', t, wasted, enoug...</td>\n",
       "      <td>[check]</td>\n",
       "      <td>[32]</td>\n",
       "      <td>[Neutral]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sentence_id                                           sentence  \\\n",
       "0              0                       Wow . . . Loved this place .   \n",
       "1              1                                Crust is not good .   \n",
       "2              2         Not tasty and the texture was just nasty .   \n",
       "3              3  Stopped by during the late May bank holiday of...   \n",
       "4              4  The selection on the menu was great and so wer...   \n",
       "..           ...                                                ...   \n",
       "995          995  I think food should have flavor and texture an...   \n",
       "996          996                          Appetite instantly gone .   \n",
       "997          997  Overall I was not impressed and would not go b...   \n",
       "998          998  The whole experience was underwhelming , and I...   \n",
       "999          999  Then , as if I hadn ' t wasted enough of my li...   \n",
       "\n",
       "                                                tokens  \\\n",
       "0                [Wow, ., ., ., Loved, this, place, .]   \n",
       "1                            [Crust, is, not, good, .]   \n",
       "2    [Not, tasty, and, the, texture, was, just, nas...   \n",
       "3    [Stopped, by, during, the, late, May, bank, ho...   \n",
       "4    [The, selection, on, the, menu, was, great, an...   \n",
       "..                                                 ...   \n",
       "995  [I, think, food, should, have, flavor, and, te...   \n",
       "996                     [Appetite, instantly, gone, .]   \n",
       "997  [Overall, I, was, not, impressed, and, would, ...   \n",
       "998  [The, whole, experience, was, underwhelming, ,...   \n",
       "999  [Then, ,, as, if, I, hadn, ', t, wasted, enoug...   \n",
       "\n",
       "                        aspect  aspect_loc               aspect_sentiment  \n",
       "0                      [place]         [7]                     [Positive]  \n",
       "1                      [Crust]         [1]                     [Negative]  \n",
       "2                    [texture]         [5]                     [Negative]  \n",
       "3                           []          []                             []  \n",
       "4    [selection, menu, prices]  [2, 5, 12]   [Neutral, Neutral, Positive]  \n",
       "..                         ...         ...                            ...  \n",
       "995    [food, flavor, texture]   [3, 6, 8]  [Neutral, Negative, Negative]  \n",
       "996                 [Appetite]         [1]                     [Negative]  \n",
       "997                         []          []                             []  \n",
       "998        [experience, Sushi]     [3, 17]            [Negative, Neutral]  \n",
       "999                    [check]        [32]                      [Neutral]  \n",
       "\n",
       "[1000 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiaoxiangma/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "aspects_loc = []\n",
    "for e, sentence in enumerate(data[:]):\n",
    "    if sentence['aspect'] != []:\n",
    "        for i in range(len(sentence['aspect'])):\n",
    "            aspects_loc.append([e,sentence['position'][i][0],sentence['aspect'][i]])\n",
    "aspects_loc = pd.DataFrame(aspects_loc, columns =['sentence_id', 'loc','aspect'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>loc</th>\n",
       "      <th>aspect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>place</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Crust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>texture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>selection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>menu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1183</th>\n",
       "      <td>995</td>\n",
       "      <td>8</td>\n",
       "      <td>texture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1184</th>\n",
       "      <td>996</td>\n",
       "      <td>1</td>\n",
       "      <td>Appetite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185</th>\n",
       "      <td>998</td>\n",
       "      <td>3</td>\n",
       "      <td>experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1186</th>\n",
       "      <td>998</td>\n",
       "      <td>17</td>\n",
       "      <td>Sushi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187</th>\n",
       "      <td>999</td>\n",
       "      <td>32</td>\n",
       "      <td>check</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1188 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentence_id  loc      aspect\n",
       "0               0    7       place\n",
       "1               1    1       Crust\n",
       "2               2    5     texture\n",
       "3               4    2   selection\n",
       "4               4    5        menu\n",
       "...           ...  ...         ...\n",
       "1183          995    8     texture\n",
       "1184          996    1    Appetite\n",
       "1185          998    3  experience\n",
       "1186          998   17       Sushi\n",
       "1187          999   32       check\n",
       "\n",
       "[1188 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aspects_loc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Clustering: Umap & HDBscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiaoxiangma/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "/Users/xiaoxiangma/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/Users/xiaoxiangma/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/Users/xiaoxiangma/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/Users/xiaoxiangma/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/Users/xiaoxiangma/.local/lib/python3.7/site-packages/py4j/java_collections.py:13: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  from collections import (\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import hdbscan\n",
    "import umap\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "\n",
    "from tqdm.notebook import trange\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, space_eval, Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiaoxiangma/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1188"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_intents = list(aspects_loc['aspect'])\n",
    "len(all_intents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
    "# model_use = hub.load(module_url)\n",
    "\n",
    "# print(f\"module {module_url} loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_st1 = SentenceTransformer('all-mpnet-base-v2')\n",
    "model_st2 = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "model_st3 = SentenceTransformer('all-distilroberta-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence_transformers.SentenceTransformer.SentenceTransformer"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model_st1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('POC_sentence_transformer.pkl', 'wb') as file:\n",
    "    pickle.dump(model_st1, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embed phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed(model, model_type, sentences):\n",
    "    if model_type == 'use':\n",
    "        embeddings = model(sentences)\n",
    "    elif model_type == 'sentence transformer':\n",
    "        embeddings = model.encode(sentences, show_progress_bar=True)\n",
    "    \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffe76c47c0c64db797760a8caf5cc801",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings_st1 = embed(model_st1, 'sentence transformer', all_intents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings_st2 = embed(model_st2, 'sentence transformer', all_intents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings_st3 = embed(model_st3, 'sentence transformer', all_intents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings = [embeddings_st1, embeddings_st2, embeddings_st3]\n",
    "\n",
    "# for embedding in embeddings:\n",
    "#     print(embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1188, 768)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_st1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def umap_fit(message_embeddings,\n",
    "                      n_neighbors,\n",
    "                      n_components, \n",
    "                      random_state = None):\n",
    "    reducer = umap.UMAP(n_neighbors = n_neighbors, \n",
    "                                n_components = n_components, \n",
    "                                metric = 'cosine', \n",
    "                                random_state=random_state).fit(message_embeddings)\n",
    "    return(reducer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer = umap_fit(embeddings_st1, n_neighbors = 15, \n",
    "                                     n_components = 5,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiaoxiangma/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "def generate_clusters(umap_reducer,\n",
    "                      message_embeddings,\n",
    "                      min_cluster_size,\n",
    "                      min_samples = None):\n",
    "    \"\"\"\n",
    "    Returns HDBSCAN objects after first performing dimensionality reduction using UMAP\n",
    "    \n",
    "    Arguments:\n",
    "        message_embeddings: embeddings to use\n",
    "        n_neighbors: int, UMAP hyperparameter n_neighbors\n",
    "        n_components: int, UMAP hyperparameter n_components\n",
    "        min_cluster_size: int, HDBSCAN hyperparameter min_cluster_size\n",
    "        min_samples: int, HDBSCAN hyperparameter min_samples\n",
    "        random_state: int, random seed\n",
    "        \n",
    "    Returns:\n",
    "        clusters: HDBSCAN object of clusters\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    umap_embeddings = umap_reducer.transform(message_embeddings)\n",
    "    \n",
    "    clusters = hdbscan.HDBSCAN(min_cluster_size = min_cluster_size, \n",
    "                               min_samples = min_samples,\n",
    "                               metric='euclidean', \n",
    "                               gen_min_span_tree=True,\n",
    "                               cluster_selection_method='eom',\n",
    "                              prediction_data=True).fit(umap_embeddings)\n",
    "    \n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_default = generate_clusters(reducer, embeddings_st1, \n",
    "                                     min_cluster_size = 10,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiaoxiangma/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HDBSCAN(algorithm='best', allow_single_cluster=False, alpha=1.0,\n",
       "        approx_min_span_tree=True, cluster_selection_epsilon=0.0,\n",
       "        cluster_selection_method='eom', core_dist_n_jobs=4,\n",
       "        gen_min_span_tree=True, leaf_size=40,\n",
       "        match_reference_implementation=False, max_cluster_size=0,\n",
       "        memory=Memory(location=None), metric='euclidean', min_cluster_size=10,\n",
       "        min_samples=None, p=None, prediction_data=True)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_clusters(clusters, prob_threshold = 0.05):\n",
    "    \"\"\"\n",
    "    Returns the label count and cost of a given clustering\n",
    "\n",
    "    Arguments:\n",
    "        clusters: HDBSCAN clustering object\n",
    "        prob_threshold: float, probability threshold to use for deciding\n",
    "                        what cluster labels are considered low confidence\n",
    "\n",
    "    Returns:\n",
    "        label_count: int, number of unique cluster labels, including noise\n",
    "        cost: float, fraction of data points whose cluster assignment has\n",
    "              a probability below cutoff threshold\n",
    "    \"\"\"\n",
    "    \n",
    "    cluster_labels = clusters.labels_\n",
    "    label_count = len(np.unique(cluster_labels))\n",
    "    total_num = len(clusters.labels_)\n",
    "    cost = (np.count_nonzero(clusters.probabilities_ < prob_threshold)/total_num)\n",
    "    \n",
    "    return label_count, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 0.0968013468013468)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_clusters(clusters_default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params, embeddings, label_lower, label_upper):\n",
    "    \"\"\"\n",
    "    Objective function for hyperopt to minimize\n",
    "\n",
    "    Arguments:\n",
    "        params: dict, contains keys for 'n_neighbors', 'n_components',\n",
    "               'min_cluster_size', 'random_state' and\n",
    "               their values to use for evaluation\n",
    "        embeddings: embeddings to use\n",
    "        label_lower: int, lower end of range of number of expected clusters\n",
    "        label_upper: int, upper end of range of number of expected clusters\n",
    "\n",
    "    Returns:\n",
    "        loss: cost function result incorporating penalties for falling\n",
    "              outside desired range for number of clusters\n",
    "        label_count: int, number of unique cluster labels, including noise\n",
    "        status: string, hypoeropt status\n",
    "\n",
    "        \"\"\"\n",
    "    reducer = umap_fit(embeddings, n_neighbors = params['n_neighbors'], \n",
    "                                 n_components = params['n_components'],\n",
    "                                 random_state = params['random_state'])\n",
    "    \n",
    "    clusters = generate_clusters(reducer, \n",
    "                                 embeddings,\n",
    "                                 min_cluster_size = params['min_cluster_size'])\n",
    "    \n",
    "    label_count, cost = score_clusters(clusters, prob_threshold = 0.05)\n",
    "    \n",
    "    #15% penalty on the cost function if outside the desired range of groups\n",
    "    if (label_count < label_lower) | (label_count > label_upper):\n",
    "        penalty = 0.15 \n",
    "    else:\n",
    "        penalty = 0\n",
    "    \n",
    "    loss = cost + penalty\n",
    "    \n",
    "    return {'loss': loss, 'label_count': label_count, 'status': STATUS_OK, 'reducer': reducer, 'HDBSCANclusters':clusters}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 0.2106060606060606,\n",
       " 'label_count': 56,\n",
       " 'status': 'ok',\n",
       " 'reducer': UMAP(angular_rp_forest=True, metric='cosine', n_components=8, n_neighbors=11, random_state=42, tqdm_kwds={'bar_format': '{desc}: {percentage:3.0f}%| {bar} {n_fmt}/{total_fmt} [{elapsed}]', 'desc': 'Epochs completed', 'disable': True}),\n",
       " 'HDBSCANclusters': HDBSCAN(algorithm='best', allow_single_cluster=False, alpha=1.0,\n",
       "         approx_min_span_tree=True, cluster_selection_epsilon=0.0,\n",
       "         cluster_selection_method='eom', core_dist_n_jobs=4,\n",
       "         gen_min_span_tree=True, leaf_size=40,\n",
       "         match_reference_implementation=False, max_cluster_size=0,\n",
       "         memory=Memory(location=None), metric='euclidean', min_cluster_size=6,\n",
       "         min_samples=None, p=None, prediction_data=True)}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objective({\n",
    "    \"n_neighbors\": 11,\n",
    "    \"n_components\": 8,\n",
    "    \"min_cluster_size\": 6,\n",
    "    \"random_state\": 42}, embeddings_st1,  label_lower = 15, label_upper = 20\n",
    "          \n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiaoxiangma/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "def bayesian_search(embeddings, space, label_lower, label_upper, max_evals=100):\n",
    "    \"\"\"\n",
    "    Perform bayesian search on hyperparameter space using hyperopt\n",
    "\n",
    "    Arguments:\n",
    "        embeddings: embeddings to use\n",
    "        space: dict, contains keys for 'n_neighbors', 'n_components',\n",
    "               'min_cluster_size', and 'random_state' and\n",
    "               values that use built-in hyperopt functions to define\n",
    "               search spaces for each\n",
    "        label_lower: int, lower end of range of number of expected clusters\n",
    "        label_upper: int, upper end of range of number of expected clusters\n",
    "        max_evals: int, maximum number of parameter combinations to try\n",
    "\n",
    "    Saves the following to instance variables:\n",
    "        best_params: dict, contains keys for 'n_neighbors', 'n_components',\n",
    "               'min_cluster_size', 'min_samples', and 'random_state' and\n",
    "               values associated with lowest cost scenario tested\n",
    "        best_clusters: HDBSCAN object associated with lowest cost scenario\n",
    "                       tested\n",
    "        trials: hyperopt trials object for search\n",
    "\n",
    "        \"\"\"\n",
    "    \n",
    "    trials = Trials()\n",
    "    fmin_objective = partial(objective, \n",
    "                             embeddings=embeddings, \n",
    "                             label_lower=label_lower,\n",
    "                             label_upper=label_upper)\n",
    "    \n",
    "    best = fmin(fmin_objective, \n",
    "                space = space, \n",
    "                algo=tpe.suggest,\n",
    "                max_evals=max_evals, \n",
    "                trials=trials)\n",
    "\n",
    "    best_params = space_eval(space, best)\n",
    "    print ('best:')\n",
    "    print (best_params)\n",
    "    print (f\"label count: {trials.best_trial['result']['label_count']}\")\n",
    "    \n",
    "\n",
    "    best_reducer = umap_fit(embeddings, n_neighbors = best_params['n_neighbors'], \n",
    "                            n_components = best_params['n_components'],\n",
    "                            random_state = best_params['random_state'])\n",
    "    \n",
    "    best_clusters = generate_clusters(best_reducer, \n",
    "                                      embeddings,\n",
    "                                      min_cluster_size = best_params['min_cluster_size'])\n",
    "    \n",
    "    \n",
    "    return best_params, best_reducer, best_clusters, trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "hspace = {\n",
    "    \"n_neighbors\": hp.choice('n_neighbors', range(3,50)),\n",
    "    \"n_components\": hp.choice('n_components', range(10,50)),\n",
    "    \"min_cluster_size\": hp.choice('min_cluster_size', range(2,16)),\n",
    "    \"random_state\": 42\n",
    "}\n",
    "\n",
    "label_lower = 10\n",
    "label_upper = 20\n",
    "max_evals = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:47<00:00, 16.77s/trial, best loss: 0.21228956228956228]\n",
      "best:\n",
      "{'min_cluster_size': 4, 'n_components': 41, 'n_neighbors': 14, 'random_state': 42}\n",
      "label count: 68\n"
     ]
    }
   ],
   "source": [
    "best_params_st1, best_reducer_st1, best_clusters_st1, trials_st1 = bayesian_search(embeddings_st1, \n",
    "                                                                 space=hspace, \n",
    "                                                                 label_lower=label_lower, \n",
    "                                                                 label_upper=label_upper, \n",
    "                                                                 max_evals=max_evals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'min_cluster_size': 4,\n",
    "#  'n_components': 41,\n",
    "#  'n_neighbors': 14,\n",
    "#  'random_state': 42}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('POC_best_reducer_st1.pkl', 'wb') as file:\n",
    "    pickle.dump(best_reducer_st1, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('POC_best_clusters_st1.pkl', 'wb') as file:\n",
    "    pickle.dump(best_clusters_st1, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_params_st2, best_reducer_st2, best_clusters_st2, trials_st2 = bayesian_search(embeddings_st2, \n",
    "#                                                                  space=hspace, \n",
    "#                                                                  label_lower=label_lower, \n",
    "#                                                                  label_upper=label_upper, \n",
    "#                                                                  max_evals=max_evals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_params_st3, best_reducer_st3, best_clusters_st3, trials_st3 = bayesian_search(embeddings_st3, \n",
    "#                                                                  space=hspace, \n",
    "#                                                                  label_lower=label_lower, \n",
    "#                                                                  label_upper=label_upper, \n",
    "#                                                                  max_evals=max_evals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'min_cluster_size': 14, 'n_components': 24, 'n_neighbors': 46, 'random_state': 42}\n",
    "label count: 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_results(df_ground, cluster_dict):\n",
    "    \"\"\"\n",
    "    Returns dataframe of all documents and each model's assigned cluster\n",
    "\n",
    "    Arguments:\n",
    "        df_ground: dataframe of original documents with associated ground truth\n",
    "                   labels\n",
    "        cluster_dict: dict, keys as column name for specific model and value as\n",
    "                      best clusters HDBSCAN object\n",
    "\n",
    "    Returns:\n",
    "        df_combined: dataframe of all documents with labels from\n",
    "                     best clusters for each model\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    df_combined = df_ground.copy()\n",
    "    \n",
    "    for key, value in cluster_dict.items():\n",
    "        df_combined[key] = value.labels_\n",
    "    \n",
    "    return df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>loc</th>\n",
       "      <th>aspect</th>\n",
       "      <th>label_st1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>place</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Crust</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>texture</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>selection</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>menu</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1183</th>\n",
       "      <td>995</td>\n",
       "      <td>8</td>\n",
       "      <td>texture</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1184</th>\n",
       "      <td>996</td>\n",
       "      <td>1</td>\n",
       "      <td>Appetite</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185</th>\n",
       "      <td>998</td>\n",
       "      <td>3</td>\n",
       "      <td>experience</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1186</th>\n",
       "      <td>998</td>\n",
       "      <td>17</td>\n",
       "      <td>Sushi</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187</th>\n",
       "      <td>999</td>\n",
       "      <td>32</td>\n",
       "      <td>check</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1188 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentence_id  loc      aspect  label_st1\n",
       "0               0    7       place          9\n",
       "1               1    1       Crust         27\n",
       "2               2    5     texture         39\n",
       "3               4    2   selection          2\n",
       "4               4    5        menu         11\n",
       "...           ...  ...         ...        ...\n",
       "1183          995    8     texture         39\n",
       "1184          996    1    Appetite         23\n",
       "1185          998    3  experience         34\n",
       "1186          998   17       Sushi         52\n",
       "1187          999   32       check         31\n",
       "\n",
       "[1188 rows x 4 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_dict = {'label_st1': best_clusters_st1}\n",
    "\n",
    "results_df = combine_results(aspects_loc, cluster_dict)\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiaoxiangma/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>loc</th>\n",
       "      <th>aspect</th>\n",
       "      <th>label_st1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Service</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>service</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>Service</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>service</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>Service</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1133</th>\n",
       "      <td>953</td>\n",
       "      <td>4</td>\n",
       "      <td>service</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1140</th>\n",
       "      <td>960</td>\n",
       "      <td>16</td>\n",
       "      <td>serving</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>961</td>\n",
       "      <td>18</td>\n",
       "      <td>service</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146</th>\n",
       "      <td>968</td>\n",
       "      <td>9</td>\n",
       "      <td>service</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1148</th>\n",
       "      <td>968</td>\n",
       "      <td>18</td>\n",
       "      <td>services</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentence_id  loc    aspect  label_st1\n",
       "10             10    1   Service          1\n",
       "16             17    7   service          1\n",
       "20             22    1   Service          1\n",
       "42             37    2   service          1\n",
       "46             39    1   Service          1\n",
       "...           ...  ...       ...        ...\n",
       "1133          953    4   service          1\n",
       "1140          960   16   serving          1\n",
       "1142          961   18   service          1\n",
       "1146          968    9   service          1\n",
       "1148          968   18  services          1\n",
       "\n",
       "[93 rows x 4 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[results_df.label_st1== 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiaoxiangma/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "aspect_clusters = results_df.groupby('label_st1').agg(group=('aspect', ','.join)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_st1</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>cranberry,interior,sever,Hiro,styrofoam,regist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>food,food,food,food,food,food,food,food,food,f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Service,service,Service,service,Service,servic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>selection,food selection,selection,selection,o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>quality,food quality,quality,quality of food,q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>62</td>\n",
       "      <td>pasta,pasta,noodles,spaghetti,pasta,pastas,pas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>63</td>\n",
       "      <td>Lobster Bisque soup,Egg Flower Soups,Albondiga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>64</td>\n",
       "      <td>red velvet cake,dessert section,chocolate milk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>65</td>\n",
       "      <td>sandwich,English muffin,bread,pork sandwich,sl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>66</td>\n",
       "      <td>batter,batter,bagels,pancakes,biscuits,dough,b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    label_st1                                              group\n",
       "0          -1  cranberry,interior,sever,Hiro,styrofoam,regist...\n",
       "1           0  food,food,food,food,food,food,food,food,food,f...\n",
       "2           1  Service,service,Service,service,Service,servic...\n",
       "3           2  selection,food selection,selection,selection,o...\n",
       "4           3  quality,food quality,quality,quality of food,q...\n",
       "..        ...                                                ...\n",
       "63         62  pasta,pasta,noodles,spaghetti,pasta,pastas,pas...\n",
       "64         63  Lobster Bisque soup,Egg Flower Soups,Albondiga...\n",
       "65         64  red velvet cake,dessert section,chocolate milk...\n",
       "66         65  sandwich,English muffin,bread,pork sandwich,sl...\n",
       "67         66  batter,batter,bagels,pancakes,biscuits,dough,b...\n",
       "\n",
       "[68 rows x 2 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aspect_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiaoxiangma/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "aspect_clusters.to_csv(\"POC_clusters.csv\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "key_phrases = [\n",
    "    'service',\n",
    "    'hygeine', \n",
    "    'appetizer', \n",
    "    'desserts',\n",
    "    'drinks/bar', \n",
    "    'food',\n",
    "    'dishes', \n",
    "    'atmosphere', \n",
    "    'menu', \n",
    "    'price', \n",
    "    'management',\n",
    "    'staff'\n",
    "]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "key_phrases_embeddings_st1 = embed(model_st1, 'sentence transformer', key_phrases)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "clusters_embedding = embed(model_st1, 'sentence transformer', aspect_clusters.group.to_list())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from numpy.linalg import norm\n",
    "def cosine_sim(A,B):\n",
    "    cosine = np.dot(A,B)/(norm(A)*norm(B))\n",
    "    return cosine"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "labels = []\n",
    "for i in range(len(clusters_embedding)):\n",
    "    labels.append([cosine_sim(phrase, clusters_embedding[i]) for phrase in key_phrases_embeddings_st1])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test = pd.DataFrame(labels, columns =key_phrases)\n",
    "test['category'] = test.idxmax(axis=1)\n",
    "test['category_strength'] = test.max(axis=1)\n",
    "test = test.round(2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "label_strength = pd.concat([aspect_clusters, test[['category','category_strength']]], axis=1)\n",
    "label_strength"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "aspects_details = results_df.merge(label_strength, on='label_st1',how='left')\n",
    "# aspects_details.drop(columns=['label_st1', 'label_st2', 'label_st3',\n",
    "#        'group'], inplace=True)\n",
    "aspects_details"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "category_column = aspects_details.groupby('sentence_id')['category'].apply(list)\n",
    "category_strength_column = aspects_details.groupby('sentence_id')['category_strength'].apply(list)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "main['category'] = category_column\n",
    "main['category_strength'] = category_strength_column"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "main"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_new_points = ['service', 'waitress', 'lobster']\n",
    "test_new_points_embeddings_st1 = embed(model_st1, 'sentence transformer', test_new_points)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_new_points_embeddings_st1_umap = best_reducer_st1.transform(test_new_points_embeddings_st1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_labels, strengths = hdbscan.approximate_predict(best_clusters_st1, test_new_points_embeddings_st1_umap)\n",
    "test_labels"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
